# 2. The lubridate package contains helpful functions to convert dates represented as strings to dates represented as dates. Convert the first_publish_date column to a type date using the mdy function.
# Converts the first_publish_date column to date type
books$first_publish_date <- mdy(books$first_publish_date)
# Displays the first few rows to verify changes
books
# 3. Using the year function in lubridate, extract the year from the first_publish_date column place it in a new column named year.
# Extracts the year and place it in a new column named 'year'
books$year <- year(books$first_publish_date)
# Displays the first few rows to check the new column
books
# 4. Reduce your dataset to only include books published between 1990 and 2020 (inclusive).
# Filter the dataset for books published between 1990 and 2020
books <- books %>% filter(year >= 1990 & year <= 2020)
# Display the first few rows to check the filtered data
books
# 5. Remove the following columns from the data set: publish_date, edition, characters, price, genres, setting, and isbn.
books <- books %>% select(-c(publish_date, edition, characters, price, genres, setting, isbn))
# Display the first few rows to check the updated data
books
# 6. Keep only books that are fewer than 1200 pages.
# Filters the 'books' data frame to include only books with fewer than 1200 pages
books <- books %>% filter(pages < 1200)
# Display the first the updated data
books
# 1. Use the glimpse function to produce a long view of the dataset.
# Gets a long view of the dataset
glimpse(books)
# 2. Use the summary function to produce a breakdown of the statistics of the dataset.
# Produces a statistical summary of the dataset
summary(books)
# 3. Create a rating histogram with the following criteria.
# – The y-axis is labeled “Number of Books.”
# – The x-axis is labeled “Rating.”
# – The title of the graph “Histogram of Book Ratings.”
# – The graph is filled with the color “red.”
# – Set a binwidth of .25.
# – Use theme_bw().
# Plots a histogram of book ratings
ggplot(books, aes(x=rating)) +
geom_histogram(fill="red", binwidth=0.25) +
labs(title="Histogram of Book Ratings", x="Rating", y="Number of Books") +
theme_bw()
# 4. Create a boxplot of the number pages per book in the dataset with the following requirements.
# – The boxplot is horizontal.
# – The x-axis is labeled “Pages.”
# – The title is “Box Plot of Page Counts.”
# – Fill the boxplot with the color magenta.
# – Use the theme theme_economist from the ggthemes package.
# install.packages('ggthemes') # nolint
# Loading the required package
library(ggthemes)
# Creates the boxplot
ggplot(books, aes(y=pages)) +
geom_boxplot(aes(fill="magenta"), color="black") +
labs(title="Box Plot of Page Counts", x="Pages") +
theme_economist() +
coord_flip()
# 5. Group the data by publisher and produce a summary data frame containing each publisher and their associated number of books in the dataset. With that data frame, make the following refinements:
# – Remove any rows that contain NAs.
# – Remove any publishers with fewer than 250 books.
# – Order the data frame by the total number of books in descending order.
# – Make the publisher into a factor with the levels defined by the current ordering of the publisher.
# – Add a column to the data frame with cumulative count of books.
# – Add a column to the data frame with the relative frequency of books.
# – Add a column to the data frame with the cumulative relative frequency of books.
# Groups the data by publisher
book_publishers <- books %>%
group_by(publisher) %>%
summarise(total_books = n()) %>%
# Removes rows containing NAs
filter(!is.na(publisher)) %>%
# Removes publishers with fewer than 250 books
filter(total_books >= 250) %>%
# Orders the data frame by the total number of books in descending order
arrange(desc(total_books)) %>%
# Makes the publisher into a factor with the levels defined by the current ordering
mutate(publisher = factor(publisher, levels = unique(publisher))) %>%
# Adds cumulative count of books
mutate(cum_count = cumsum(total_books)) %>%
# Adds relative frequency of books
mutate(rel_freq = total_books / sum(total_books)) %>%
# Adds cumulative relative frequency of books
mutate(cum_freq = cumsum(rel_freq))
# Displays the refined data frame
book_publishers
# 6. Using the data frame constructed in the prior problem, create a Pareto Chart with an ogive of cumulative counts formatted with the following additional criteria:
# – The bars are filled with the color cyan.
# – The x-axis label is “Publisher.”
# – The y-axis label is “Number of Books.”
# – The title is “Pareto and Ogive of Publisher Book Counts (1990 - 2020).”
# – Use the theme theme_clean().
# – Rotate the x-axis labels by 45 degrees.
# Creates the Pareto Chart with an ogive of cumulative counts
pareto_chart <- ggplot(book_publishers, aes(x = reorder(publisher, -total_books), y = total_books)) +
# Adds bars
geom_bar(stat = "identity", fill = "cyan") +
# Adds ogive line for cumulative counts
geom_line(aes(y = cum_count, group = 1), color = "blue", size = 1) +
# Adds points for each cumulative count
geom_point(aes(y = cum_count), color = "red", size = 3) +
# Sets labels and title
labs(
x = "Publisher",
y = "Number of Books",
title = "Pareto and Ogive of Publisher Book Counts (1990 - 2020)"
) +
# Uses the theme_clean
theme_clean() +
# Rotates x-axis labels by 45 degrees
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Displays the Pareto Chart
pareto_chart
# 7. Create a scatter plot of pages vs. rating for the books data frame with the following requirements:
# – Color the points based on the year of publication.
# – The x-axis is labeled “Pages.”
# – The y-axis is labeled “Rating.”
# – The graph is titled “Scatter Plot of Pages vs. Rating.”
# – Use the theme theme_tufte().
# Creates the scatter plot
scatter_plot <- ggplot(books, aes(x = pages, y = rating, color = as.factor(year))) +
# Adds scatter points
geom_point(alpha = 0.6) +
# Sets labels and title
labs(
x = "Pages",
y = "Rating",
title = "Scatter Plot of Pages vs. Rating",
color = "Publication Year"
) +
# Uses the theme_tufte
theme_tufte()
# Displays the scatter plot
scatter_plot
# 8. Create a data frame from the books data frame that contains a count of the number of books by year and the average rating for each year.
# Uses dplyr to group and summarize
by_year <- books %>%
group_by(year) %>%
summarise(
total_books = n(),
avg_rating = mean(rating, na.rm = TRUE)
)
# Views the created data frame
by_year
# 9. Create a line plot with from this data frame with points representing the counts per year from 1990 - 2020. Color the points for each year with the average rating. The size of each data point should vary with the average rating. Format with the following specifications:
# – The graph is titled “Total Number of Books Rated Per Year.”
# – The theme is theme_excel_new().
# Creates the line plot
ggplot(data = by_year, aes(x = year, y = total_books, color = avg_rating, size = avg_rating)) +
geom_line() +
geom_point() +
scale_color_gradient(low = "blue", high = "red") + # Gradient color for average rating
labs(
title = "Total Number of Books Rated Per Year",
x = "Year",
y = "Number of Books"
) +
theme_excel_new() +
guides(color = guide_legend(title = "Avg Rating"), size = guide_legend(title = "Avg Rating"))
# 10. R has built-in functions to computer the sample mean (mean), sample variance (var), and sample standard deviation (sd). The function 'calc_mean' below takes in a vector of values and returns the average. Using the function as a template, create two more functions; one to compute the population variance (pop_var) and the other one to compute the population standard deviation (sd_var). See module 4's slides for the difference between sample and population variance and standard deviation. You may not use the three built-in functions listed above, but may use other built-in functions. All three functions should accept a single vector of values and return the corresponding computed result.
# Provided function to calculate mean
calc_mean <- function(values) {
total <- sum(values)
return(total / length(values))
}
# Function to compute population variance
pop_var <- function(values) {
mean_value <- calc_mean(values)
squared_diffs <- (values - mean_value)^2
return(sum(squared_diffs) / length(values))
}
# Function to compute population standard deviation
pop_sd <- function(values) {
variance <- pop_var(values)
return(sqrt(variance))
}
# 11. Consider the complete dataset of books to be the population you are analyzing. Compute population stats for the average, variance, and standard deviation of the book rating.
# Computes population mean for book ratings
average_rating <- calc_mean(books$rating)
# Computes population variance for book ratings
variance_rating <- pop_var(books$rating)
# Computes population standard deviation for book ratings
std_dev_rating <- pop_sd(books$rating)
# Prints
average_rating
variance_rating
std_dev_rating
# 12. Create three samples of size 100 from the books data frame using the function sample(df$rating, size = 100, replace = FALSE). For each sample, compute sample statistics for mean, variance and standard deviation of the book rating. Compare these results with the population stats in your report.
# Takes three samples
sample1 <- sample(books$rating, size = 100, replace = FALSE)
sample2 <- sample(books$rating, size = 100, replace = FALSE)
sample3 <- sample(books$rating, size = 100, replace = FALSE)
# Computes statistics for Sample 1
mean_sample1 <- mean(sample1)
var_sample1 <- var(sample1)
sd_sample1 <- sd(sample1)
# Computes statistics for Sample 2
mean_sample2 <- mean(sample2)
var_sample2 <- var(sample2)
sd_sample2 <- sd(sample2)
# Computes statistics for Sample 3
mean_sample3 <- mean(sample3)
var_sample3 <- var(sample3)
sd_sample3 <- sd(sample3)
# Displays
mean_sample1
var_sample1
sd_sample1
mean_sample2
var_sample2
sd_sample2
mean_sample3
var_sample3
sd_sample3
# 13. Create one or more additional visualizations based on the existing data or additional analysis that you perform.
# Groups data by year and calculating the average rating
avg_rating_by_year <- books %>%
group_by(year) %>%
summarise(average_rating = mean(rating, na.rm = TRUE))
# Plots the data
ggplot(avg_rating_by_year, aes(x=year, y=average_rating)) +
geom_line(color="blue") +
geom_point(color="red") +
labs(title="Average Rating per Year", x="Year", y="Average Rating") +
theme_minimal()
# 14. Write an executive summary report that contains an overview of your analysis, the visualizations you created with textual descriptions of key takeaways, and any key statistics that were computed in your analysis.
# Run this cell to check your answers
library(pacman)
p_load(testthat)
p_load(tidyverse)
p_load(lubridate)
p_load(ggplot2)
# p_load(janitor)
# p_load(dplyr)
# p_load(tidyr)
test_file("project3_tests.R")
# install.packages("pacman")
cat("\014") # clears console
rm(list = ls()) # clears global environment
try(dev.off(dev.list()["RStudioGD"]), silent = TRUE) # clears plots
try(p_unload(p_loaded(), character.only = TRUE), silent = TRUE) # clears packages
options(scipen = 100) # disables scientific notation for entire R session
# You should do this line only once in the entire course.
# install.packages("pacman")
library(pacman)
p_load(testthat)
p_load(tidyverse)
p_load(lubridate)
p_load(ggplot2)
p_load(janitor)
# p_load(dplyr)
# p_load(tidyr)
# 1. Download the file books.csv from Canvas and read the dataset into R.
# Reads the CSV file into a dataframe called 'books'
books <- read.csv("books.csv")
# Displays the first few rows of the dataframe to verify it was read correctly
books
# 1. The janitor package contains helpful functions that perform basic maintenance of your data frame. Use the clean_names function to standardize the names in your data frame.
# Uses clean_names function to standardize the column names
books <- clean_names(books)
# Displays the first few rows to check the cleaned column names
books
# install.packages("pacman")
cat("\014") # clears console
rm(list = ls()) # clears global environment
try(dev.off(dev.list()["RStudioGD"]), silent = TRUE) # clears plots
try(p_unload(p_loaded(), character.only = TRUE), silent = TRUE) # clears packages
options(scipen = 100) # disables scientific notation for entire R session
# You should do this line only once in the entire course.
# install.packages("pacman")
library(pacman)
p_load(testthat)
p_load(tidyverse)
p_load(lubridate)
p_load(ggplot2)
p_load(janitor)
# p_load(dplyr)
# p_load(tidyr)
# 1. Download the file books.csv from Canvas and read the dataset into R.
# Reads the CSV file into a dataframe called 'books'
books <- read.csv("books.csv")
# Displays the first few rows of the dataframe to verify it was read correctly
books
# 1. The janitor package contains helpful functions that perform basic maintenance of your data frame. Use the clean_names function to standardize the names in your data frame.
# Uses clean_names function to standardize the column names
books <- clean_names(books)
# Displays the first few rows to check the cleaned column names
books
# 2. The lubridate package contains helpful functions to convert dates represented as strings to dates represented as dates. Convert the first_publish_date column to a type date using the mdy function.
# Converts the first_publish_date column to date type
books$first_publish_date <- mdy(books$first_publish_date)
# Displays the first few rows to verify changes
books
# 3. Using the year function in lubridate, extract the year from the first_publish_date column place it in a new column named year.
# Extracts the year and place it in a new column named 'year'
books$year <- year(books$first_publish_date)
# Displays the first few rows to check the new column
books
# 4. Reduce your dataset to only include books published between 1990 and 2020 (inclusive).
# Filter the dataset for books published between 1990 and 2020
books <- books %>% filter(year >= 1990 & year <= 2020)
# Display the first few rows to check the filtered data
books
# 5. Remove the following columns from the data set: publish_date, edition, characters, price, genres, setting, and isbn.
books <- books %>% select(-c(publish_date, edition, characters, price, genres, setting, isbn))
# Display the first few rows to check the updated data
books
# 6. Keep only books that are fewer than 1200 pages.
# Filters the 'books' data frame to include only books with fewer than 1200 pages
books <- books %>% filter(pages < 1200)
# Display the first the updated data
books
# 1. Use the glimpse function to produce a long view of the dataset.
# Gets a long view of the dataset
glimpse(books)
# 2. Use the summary function to produce a breakdown of the statistics of the dataset.
# Produces a statistical summary of the dataset
summary(books)
# 3. Create a rating histogram with the following criteria.
# – The y-axis is labeled “Number of Books.”
# – The x-axis is labeled “Rating.”
# – The title of the graph “Histogram of Book Ratings.”
# – The graph is filled with the color “red.”
# – Set a binwidth of .25.
# – Use theme_bw().
# Plots a histogram of book ratings
ggplot(books, aes(x=rating)) +
geom_histogram(fill="red", binwidth=0.25) +
labs(title="Histogram of Book Ratings", x="Rating", y="Number of Books") +
theme_bw()
# 4. Create a boxplot of the number pages per book in the dataset with the following requirements.
# – The boxplot is horizontal.
# – The x-axis is labeled “Pages.”
# – The title is “Box Plot of Page Counts.”
# – Fill the boxplot with the color magenta.
# – Use the theme theme_economist from the ggthemes package.
# install.packages('ggthemes') # nolint
# Loading the required package
library(ggthemes)
# Creates the boxplot
ggplot(books, aes(y=pages)) +
geom_boxplot(aes(fill="magenta"), color="black") +
labs(title="Box Plot of Page Counts", x="Pages") +
theme_economist() +
coord_flip()
# 5. Group the data by publisher and produce a summary data frame containing each publisher and their associated number of books in the dataset. With that data frame, make the following refinements:
# – Remove any rows that contain NAs.
# – Remove any publishers with fewer than 250 books.
# – Order the data frame by the total number of books in descending order.
# – Make the publisher into a factor with the levels defined by the current ordering of the publisher.
# – Add a column to the data frame with cumulative count of books.
# – Add a column to the data frame with the relative frequency of books.
# – Add a column to the data frame with the cumulative relative frequency of books.
# Groups the data by publisher
book_publishers <- books %>%
group_by(publisher) %>%
summarise(total_books = n()) %>%
# Removes rows containing NAs
filter(!is.na(publisher)) %>%
# Removes publishers with fewer than 250 books
filter(total_books >= 250) %>%
# Orders the data frame by the total number of books in descending order
arrange(desc(total_books)) %>%
# Makes the publisher into a factor with the levels defined by the current ordering
mutate(publisher = factor(publisher, levels = unique(publisher))) %>%
# Adds cumulative count of books
mutate(cum_count = cumsum(total_books)) %>%
# Adds relative frequency of books
mutate(rel_freq = total_books / sum(total_books)) %>%
# Adds cumulative relative frequency of books
mutate(cum_freq = cumsum(rel_freq))
# Displays the refined data frame
book_publishers
# 6. Using the data frame constructed in the prior problem, create a Pareto Chart with an ogive of cumulative counts formatted with the following additional criteria:
# – The bars are filled with the color cyan.
# – The x-axis label is “Publisher.”
# – The y-axis label is “Number of Books.”
# – The title is “Pareto and Ogive of Publisher Book Counts (1990 - 2020).”
# – Use the theme theme_clean().
# – Rotate the x-axis labels by 45 degrees.
# Creates the Pareto Chart with an ogive of cumulative counts
pareto_chart <- ggplot(book_publishers, aes(x = reorder(publisher, -total_books), y = total_books)) +
# Adds bars
geom_bar(stat = "identity", fill = "cyan") +
# Adds ogive line for cumulative counts
geom_line(aes(y = cum_count, group = 1), color = "blue", size = 1) +
# Adds points for each cumulative count
geom_point(aes(y = cum_count), color = "red", size = 3) +
# Sets labels and title
labs(
x = "Publisher",
y = "Number of Books",
title = "Pareto and Ogive of Publisher Book Counts (1990 - 2020)"
) +
# Uses the theme_clean
theme_clean() +
# Rotates x-axis labels by 45 degrees
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Displays the Pareto Chart
pareto_chart
# 7. Create a scatter plot of pages vs. rating for the books data frame with the following requirements:
# – Color the points based on the year of publication.
# – The x-axis is labeled “Pages.”
# – The y-axis is labeled “Rating.”
# – The graph is titled “Scatter Plot of Pages vs. Rating.”
# – Use the theme theme_tufte().
# Creates the scatter plot
scatter_plot <- ggplot(books, aes(x = pages, y = rating, color = as.factor(year))) +
# Adds scatter points
geom_point(alpha = 0.6) +
# Sets labels and title
labs(
x = "Pages",
y = "Rating",
title = "Scatter Plot of Pages vs. Rating",
color = "Publication Year"
) +
# Uses the theme_tufte
theme_tufte()
# Displays the scatter plot
scatter_plot
# 8. Create a data frame from the books data frame that contains a count of the number of books by year and the average rating for each year.
# Uses dplyr to group and summarize
by_year <- books %>%
group_by(year) %>%
summarise(
total_books = n(),
avg_rating = mean(rating, na.rm = TRUE)
)
# Views the created data frame
by_year
# 9. Create a line plot with from this data frame with points representing the counts per year from 1990 - 2020. Color the points for each year with the average rating. The size of each data point should vary with the average rating. Format with the following specifications:
# – The graph is titled “Total Number of Books Rated Per Year.”
# – The theme is theme_excel_new().
# Creates the line plot
ggplot(data = by_year, aes(x = year, y = total_books, color = avg_rating, size = avg_rating)) +
geom_line() +
geom_point() +
scale_color_gradient(low = "blue", high = "red") + # Gradient color for average rating
labs(
title = "Total Number of Books Rated Per Year",
x = "Year",
y = "Number of Books"
) +
theme_excel_new() +
guides(color = guide_legend(title = "Avg Rating"), size = guide_legend(title = "Avg Rating"))
# 10. R has built-in functions to computer the sample mean (mean), sample variance (var), and sample standard deviation (sd). The function 'calc_mean' below takes in a vector of values and returns the average. Using the function as a template, create two more functions; one to compute the population variance (pop_var) and the other one to compute the population standard deviation (sd_var). See module 4's slides for the difference between sample and population variance and standard deviation. You may not use the three built-in functions listed above, but may use other built-in functions. All three functions should accept a single vector of values and return the corresponding computed result.
# Provided function to calculate mean
calc_mean <- function(values) {
total <- sum(values)
return(total / length(values))
}
# Function to compute population variance
pop_var <- function(values) {
mean_value <- calc_mean(values)
squared_diffs <- (values - mean_value)^2
return(sum(squared_diffs) / length(values))
}
# Function to compute population standard deviation
pop_sd <- function(values) {
variance <- pop_var(values)
return(sqrt(variance))
}
# 11. Consider the complete dataset of books to be the population you are analyzing. Compute population stats for the average, variance, and standard deviation of the book rating.
# Computes population mean for book ratings
average_rating <- calc_mean(books$rating)
# Computes population variance for book ratings
variance_rating <- pop_var(books$rating)
# Computes population standard deviation for book ratings
std_dev_rating <- pop_sd(books$rating)
# Prints
average_rating
variance_rating
std_dev_rating
# 12. Create three samples of size 100 from the books data frame using the function sample(df$rating, size = 100, replace = FALSE). For each sample, compute sample statistics for mean, variance and standard deviation of the book rating. Compare these results with the population stats in your report.
# Takes three samples
sample1 <- sample(books$rating, size = 100, replace = FALSE)
sample2 <- sample(books$rating, size = 100, replace = FALSE)
sample3 <- sample(books$rating, size = 100, replace = FALSE)
# Computes statistics for Sample 1
mean_sample1 <- mean(sample1)
var_sample1 <- var(sample1)
sd_sample1 <- sd(sample1)
# Computes statistics for Sample 2
mean_sample2 <- mean(sample2)
var_sample2 <- var(sample2)
sd_sample2 <- sd(sample2)
# Computes statistics for Sample 3
mean_sample3 <- mean(sample3)
var_sample3 <- var(sample3)
sd_sample3 <- sd(sample3)
# Displays
mean_sample1
var_sample1
sd_sample1
mean_sample2
var_sample2
sd_sample2
mean_sample3
var_sample3
sd_sample3
# 13. Create one or more additional visualizations based on the existing data or additional analysis that you perform.
# Groups data by year and calculating the average rating
avg_rating_by_year <- books %>%
group_by(year) %>%
summarise(average_rating = mean(rating, na.rm = TRUE))
# Plots the data
ggplot(avg_rating_by_year, aes(x=year, y=average_rating)) +
geom_line(color="blue") +
geom_point(color="red") +
labs(title="Average Rating per Year", x="Year", y="Average Rating") +
theme_minimal()
# 14. Write an executive summary report that contains an overview of your analysis, the visualizations you created with textual descriptions of key takeaways, and any key statistics that were computed in your analysis.
